# S3
Simple Storage service - object based storage.
Data is spread across multiple devices and facilities.

Different to block base storage. 

Don't use it to boot a volume, run a database or OS.


* Upload files from 0b to 5terabytes.

* Unlimited!

* buckets are like folders. 

* S3 namespaces are globally created, theres only one name.

for example: https://s3-eu-weast-1.amazonaws.com/douglasbrauner

it replys with 200 when the file is uploaded.

# Data consistency

* read after write consistency for put operations on new objects - Eventual Consistency for overwriting with PUTS and Deletes. - it can take some times to propagate. 
* new files are instantly - modifications and deletions may take a time. but this is miliseconds, you can get the old data. but no partial or corrupted data is provided, you always get the new or the old.


# Object based store
Key - simple name for the object
Value - your data in a sequence of bytes
Version ID - 
Metadata  - data about your data. timestamp, etc.

Important thing about names (keys) - in S3, files are stored accordingly its name organization, so files with similar name, like a timestamp at begining, will be stored closed to each one, which could lead to performance bottleneck for reading operations, what you can do instead is to include a hash or salt at the begining of the file, to ensure it will be stored evenly in the s3.

there is also subresources, like access control lists, torrent config.

guarantee SLA of 99.9%, but durability for S3 is 9x11 (99.999999999%)

You have also encryption and bucket access control.

S3 normal - with the availability already explained.
S3 IA - infrequent accessed. data that is less accessed but when you need it should be fast, so it is cheaper than s3, but you will be charged a fee in read operations.  Example are files you need, like anual taxes reporting, or even the payroll. 

RRS - Reduced Redundancy Storage - the availability, but less durability, only 99,99. it is cheaper. for example for generated files (pdf from latex).

Glacier - cold storage - it takes 3 to 5 hours to retrieve from this storage. archival only! 1 cent per gb per month.


# Charges
* Storage - amount of space you are using
* requests - operations, even gets.
* Storage management pricing - you can put takes on your data, so you can track the costs associated, it also have a cost for that.
* Data transfer pricing - inserting objects is free, however if you need to copy/move it to another region/bucket, you pay for that.
* Transfer Acceleration - it is a technology from AWS that allows you to upload files faster to a remote S3 bucket in another region, for example in US, if you are in brazil, the files will be uploaded to the edge locations, which are closer, then they will be transfered to the remote S3.

# Exam tips
* NO OS, no database, only files!
* 0b to 5tb.
* bucket name is unique globally
* READ the S3 FAQ!

# Hands on
Management of buckets is done globally, so you can manage all in the same place without using specific region.
system permissions are like logs from applications to use it, disabled by default.

## Permissions
You have three types of permissions for files under s3:
* Owner access - configure which account is owner and permissions;
* Access for AWS account - you can add others account to make operations on this file;
* Public access - for accessing the data with the given url.

You can add your own metadata to files. 
you can change the storage class for individual files. 
Access can be configure with ACL - access control lists or Policies, which is a json file with the permissions (aws can generate that for you)























